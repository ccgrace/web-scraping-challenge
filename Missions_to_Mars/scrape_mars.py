from splinter import Browserfrom bs4 import BeautifulSoup as bsfrom webdriver_manager.chrome import ChromeDriverManagerimport pandas as pddef scrape():        # Mars News Scrape    executable_path = {'executable_path':ChromeDriverManager().install()}    browser = Browser('chrome', **executable_path, headless=False)    # identifies url and orders browser to navigate there    url = 'https://redplanetscience.com/'    browser.visit(url)        # Scrapes the html and forms soup object    html = browser.html    soup = bs(html, "html.parser")        # searches html objects to find article segments    news_title = soup.find_all('div', class_='content_title')[0].text    news_p = soup.find_all('div', class_='article_teaser_body')[0].text        browser.quit()            # JPL Mares Space Image Scrape    executable_path = {'executable_path':ChromeDriverManager().install()}    browser = Browser('chrome', **executable_path, headless=False)        url = 'https://spaceimages-mars.com/'    browser.visit(url)        browser.links.find_by_partial_text('FULL IMAGE').click()        # Scrapes the html and forms soup object    html = browser.html    soup = bs(html, "html.parser")        # searches html objects to find article segments    featured_image_url = soup.find('img', class_="fancybox-image")['src']        browser.quit()            # Mars Facts Scrape    table_url = 'https://galaxyfacts-mars.com/'    tables = pd.read_html(table_url)    type(tables)    list        facts_df = tables[0]    facts = facts_df.set_index(0)            # Mars Hemispheres Scrape    executable_path = {'executable_path':ChromeDriverManager().install()}    browser = Browser('chrome', **executable_path, headless=False)        url = 'https://marshemispheres.com/'    browser.visit(url)        html = browser.html    soup = bs(html, "html.parser")        items = soup.find_all('h3')        counter = 0    hemisphere_image_urls = []        try:        for item in items:            img_title = items[counter].text            browser.links.find_by_partial_text('Hemisphere Enhanced')[counter].click()            html = browser.html            soup = bs(html, "html.parser")            img_url = soup.find('img', class_='wide-image')['src']            browser.visit(url)            html = browser.html            soup = bs(html, "html.parser")            counter = counter + 1            dict = {'title':img_title,                    'img_url': img_url}            hemisphere_image_urls.append(dict)    except ElementDoesNotExist:        pass        browser.quit()        # Store data in dictionary    scrape_dict = {        'news_title':news_title,        'news_preview':news_p,        'featured_img_url':featured_image_url,        'facts': facts,        'hemisphere_urls':hemisphere_image_urls        }            # Return results    return scrape_dict